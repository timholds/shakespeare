{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Clean Poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That thereby beauty's rose might never die,\n"
     ]
    }
   ],
   "source": [
    "def read_files(file_in):\n",
    "    \n",
    "    '''Takes a text file of poems, returns a list of poems with titles and no punctuation'''\n",
    "    \n",
    "    poems = []    \n",
    "    with open(file_in, 'r') as file:\n",
    "        poems_raw = file.read().split('\\n\\n')\n",
    "        poems_clean = [poem.split('\\n')for poem in poems_raw]\n",
    "        for i in range(0, (int(len(poems_clean) - 1)), 2):\n",
    "            poem = poems_clean[i+1]\n",
    "            poems.append(poem)\n",
    "\n",
    "    return poems\n",
    "poems_raw = read_files('sonnets.txt')\n",
    "print(poems_raw[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "import string\n",
    "def clean(poems):\n",
    "   \n",
    "    '''Takes a list of poems, \n",
    "    Returns a list of poems with punctuation removed from each poem\n",
    "    Make all words lowercase '''\n",
    "    \n",
    "    poems_clean = []\n",
    "    for poem in poems:\n",
    "        poem_clean = []\n",
    "        for line in poem:\n",
    "            poem_no_punc = line.translate(str.maketrans('','',string.punctuation))\n",
    "            clean_line = poem_no_punc.rstrip().lower()\n",
    "            poem_clean.append(clean_line)\n",
    "            \n",
    "        poems_clean.append(poem_clean)\n",
    "\n",
    "    return poems_clean\n",
    "poems_clean = clean(poems_raw)\n",
    "#poems_clean[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import pronouncing as prn\n",
    "def poems_to_phonemes(poems):    \n",
    "    slang = []\n",
    "    for poem in poems:\n",
    "        poem_phonemes = []\n",
    "        for line in poem:\n",
    "            line_phones = \"\"\n",
    "            for word in line:\n",
    "                p = prn.phones_for_word(word)\n",
    "\n",
    "                if len(p) == 1:\n",
    "                    for item in p:\n",
    "                        line_phones = line_phones + \" \" + item\n",
    "                elif len(p) > 1:\n",
    "                    # TODO fix this hack by figuring out which pronunciation is best instead of just choosing the 1st\n",
    "                    for item in p:\n",
    "                        line_phones = line_phones + \" \" + item\n",
    "                else: # the word is not in the pronouncing dictionary\n",
    "                    slang.append(word)\n",
    "                    line_phones = line_phones + word\n",
    "\n",
    "                poem_phonemes.append(line_phones)\n",
    "            poems.append(poem_phonemes)\n",
    "\n",
    "        #poem_phonemes.append(poem_phones)\n",
    "\n",
    "    return poem_phonemes, slang \n",
    "phones, slang = poems_to_phonemes(poems_clean)\n",
    "phones[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return dm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Trees and Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronouncing as prn\n",
    "import string\n",
    "import itertools\n",
    "import torch\n",
    "from collections import Counter\n",
    "import skbio\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "import gensim\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def read_files(file_in):\n",
    "    '''Takes a text file of poems, returns a list of poems with titles and no punctuation'''\n",
    "    poems_titled = []    \n",
    "    with open(file_in, 'r') as file:\n",
    "        poems_raw = file.read().split('\\n\\n')\n",
    "\n",
    "        # Poems and their titles got split up when parsing - reunite them\n",
    "        for i in range(0, (int(len(poems_raw) - 1)), 2):\n",
    "            poem_with_title = poems_raw[i] + \" \" + poems_raw[i+1]\n",
    "            poems_titled.append(poem_with_title)\n",
    "\n",
    "    return poems_titled\n",
    "poems_punc = read_files('sonnets.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(poems_punc):\n",
    "\n",
    "    '''Takes a list of poems, and returns a list of poems with punctuation removed from each poem'''\n",
    "\n",
    "    for poem in poems_punc:\n",
    "        poem_phonemes = []\n",
    "        poem_no_punc = poem.translate(str.maketrans('','',string.punctuation))\n",
    "        poems_no_punc.append(poem_no_punc)\n",
    "\n",
    "    return poems_no_punc\n",
    "poems_no_punc = remove_punctuation(poems_punc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Poem Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     9,
     23,
     34,
     44,
     71
    ]
   },
   "outputs": [],
   "source": [
    "class Poems(poems):\n",
    "    \n",
    "    def __init__(self, poems):\n",
    "        self.poems = poems\n",
    "        self.lines = [[]]\n",
    "        self.poem_words = []\n",
    "        self.poem_phonemes = []\n",
    "        self.slang = [] \n",
    "                  \n",
    "    def text_to_poems(self, file_in):\n",
    "        \n",
    "        '''Takes a text file of poems, returns a list of poems with titles and no punctuation'''\n",
    "        \n",
    "        with open(file_in, 'r') as file:\n",
    "            poems_raw = file.read().split('\\n\\n')\n",
    "\n",
    "            # Poems and their titles got split up when parsing - reunite them\n",
    "            for i in range(0, (int(len(poems_raw) - 1)), 2):\n",
    "                poem_with_title = poems_raw[i] + \" \" + poems_raw[i+1]\n",
    "                self.poems_titled.append(poem_with_title)\n",
    "\n",
    "        return self.poems_titled\n",
    "         \n",
    "    def remove_punctuation(self, poems_punc):\n",
    "\n",
    "        '''Takes a list of poems, and returns a list of poems with punctuation removed from each poem'''\n",
    "\n",
    "        for poem in poems_punc:\n",
    "            poem_phonemes = []\n",
    "            poem_no_punc = poem.translate(str.maketrans('','',string.punctuation))\n",
    "            self.poems_no_punc.append(poem_no_punc)\n",
    "\n",
    "        return self.poems_no_punc\n",
    "\n",
    "    def poems_to_words(self, poems):\n",
    "        \n",
    "        '''Make each line into a list of word and mke all words lowercase. Returns list of lists '''\n",
    "        for poem in poems:\n",
    "            lines = list(map(lambda x:x.lower(), poem.split('\\n')))\n",
    "            poem_word_list = [l.split() for l in lines]\n",
    "            self.poem_words.append(poem_word_list)\n",
    "\n",
    "        return self.poem_words\n",
    "    \n",
    "    def poem_to_phonemes(self, lines):\n",
    "        '''Make all words lowercase and make each line into a list of word. Returns list of lists '''\n",
    "        for poem in poems:\n",
    "            poem_phones = []\n",
    "            \n",
    "            for line in poem:\n",
    "                line_phones = \"\"\n",
    "                for word in line:\n",
    "                    p = prn.phones_for_word(word)\n",
    "\n",
    "                    if len(p) == 1:\n",
    "                        for item in p:\n",
    "                            line_phones = line_phones + \" \" + item\n",
    "                    elif len(p) > 1:\n",
    "                        # TODO fix this hack by figuring out which pronunciation is best instead of just choosing the 1st\n",
    "                        for item in p:\n",
    "                            line_phones = line_phones + \" \" + item\n",
    "                    else: # the word is not in the pronouncing dictionary\n",
    "                        self.lang.append(word)\n",
    "                        line_phones = line_phones + word\n",
    "\n",
    "                poem_phones.append(line_phones)\n",
    "\n",
    "            phonemes.append(poem_phones)\n",
    "\n",
    "        return self.poem_phonemes\n",
    "    \n",
    "    def poems_to_phonemes(self, poems):    \n",
    "        for poem in poems:\n",
    "            poem_phones = []\n",
    "            for line in poem:\n",
    "                line_phones = \"\"\n",
    "                for word in line:\n",
    "                    p = prn.phones_for_word(word)\n",
    "\n",
    "                    if len(p) == 1:\n",
    "                        for item in p:\n",
    "                            line_phones = line_phones + \" \" + item\n",
    "                    elif len(p) > 1:\n",
    "                        # TODO fix this hack by figuring out which pronunciation is best instead of just choosing the 1st\n",
    "                        for item in p:\n",
    "                            line_phones = line_phones + \" \" + item\n",
    "                    else: # the word is not in the pronouncing dictionary\n",
    "                        self.slang.append(word)\n",
    "                        line_phones = line_phones + word\n",
    "\n",
    "                poem_phones.append(line_phones)\n",
    "\n",
    "            self.poem_phonemes.append(poem_phones)\n",
    "\n",
    "        return self.poem_phonemes, self.slang   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     10,
     14,
     22
    ]
   },
   "outputs": [],
   "source": [
    "class Poems2():\n",
    "    \n",
    "    def __init__():\n",
    "        self.poems = []\n",
    "        self.lines = []\n",
    "        self.words = []\n",
    "        self.stresses = []\n",
    "        self.phonemes = []\n",
    "        self.slang = []\n",
    "        \n",
    "    def to_lines(self):\n",
    "        pass\n",
    "        return self.lines\n",
    "    \n",
    "    def to_words(self):\n",
    "        pass\n",
    "        return self.words\n",
    "    \n",
    "     def to_stresses(self):\n",
    "        pass\n",
    "        return self.stresses\n",
    "    \n",
    "    def to_phonemes(self):\n",
    "        pass\n",
    "        return self.phonemes, self.slang\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' AY1', ' ', ' EH1 F', ' AA1 R', ' OW1', ' EH1 M', ' ', ' EH1 F', ' AH0 EY1', ' AY1', ' AA1 R', ' IY1', ' EH1 S', ' T IY1', ' ', ' S IY1', ' AA1 R', ' IY1', ' AH0 EY1', ' T IY1', ' Y UW1', ' AA1 R', ' IY1', ' EH1 S', ' ', ' D AH1 B AH0 L Y UW0', ' IY1', ' ', ' D IY1', ' IY1', ' EH1 S', ' AY1', ' AA1 R', ' IY1', ' ', ' AY1', ' EH1 N', ' S IY1', ' AA1 R', ' IY1', ' AH0 EY1', ' EH1 S', ' IY1', '\\n', ' T IY1', ' EY1 CH', ' AH0 EY1', ' T IY1', ' ', ' T IY1', ' EY1 CH', ' IY1', ' AA1 R', ' IY1', ' B IY1', ' W AY1', ' ', ' B IY1', ' IY1', ' AH0 EY1', ' Y UW1', ' T IY1', ' W AY1', ' EH1 S', ' ', ' AA1 R', ' OW1', ' EH1 S', ' IY1', ' ', ' EH1 M', ' AY1', ' JH IY1', ' EY1 CH', ' T IY1', ' ', ' EH1 N', ' IY1', ' V IY1', ' IY1', ' AA1 R', ' ', ' D IY1', ' AY1', ' IY1', '\\n', ' B IY1', ' Y UW1', ' T IY1', ' ', ' AH0 EY1', ' EH1 S', ' ', ' T IY1', ' EY1 CH', ' IY1', ' ', ' AA1 R', ' AY1', ' P IY1', ' IY1', ' AA1 R', ' ', ' EH1 S', ' EY1 CH', ' OW1', ' Y UW1', ' EH1 L', ' D IY1', ' ', ' B IY1', ' W AY1', ' ', ' T IY1', ' AY1', ' EH1 M', ' IY1', ' ', ' D IY1', ' IY1', ' S IY1', ' IY1', ' AH0 EY1', ' EH1 S', ' IY1', '\\n', ' EY1 CH', ' AY1', ' EH1 S', ' ', ' T IY1', ' IY1', ' EH1 N', ' D IY1', ' IY1', ' AA1 R', ' ', ' EY1 CH', ' IY1', ' AY1', ' AA1 R', ' ', ' EH1 M', ' AY1', ' JH IY1', ' EY1 CH', ' T IY1', ' ', ' B IY1', ' IY1', ' AH0 EY1', ' AA1 R', ' ', ' EY1 CH', ' AY1', ' EH1 S', ' ', ' EH1 M', ' IY1', ' EH1 M', ' OW1', ' AA1 R', ' W AY1', '\\n', ' B IY1', ' Y UW1', ' T IY1', ' ', ' T IY1', ' EY1 CH', ' OW1', ' Y UW1', ' ', ' S IY1', ' OW1', ' EH1 N', ' T IY1', ' AA1 R', ' AH0 EY1', ' S IY1', ' T IY1', ' IY1', ' D IY1', ' ', ' T IY1', ' OW1', ' ', ' T IY1', ' EY1 CH', ' AY1', ' EH1 N', ' IY1', ' ', ' OW1', ' D AH1 B AH0 L Y UW0', ' EH1 N', ' ', ' B IY1', ' AA1 R', ' AY1', ' JH IY1', ' EY1 CH', ' T IY1', ' ', ' IY1', ' W AY1', ' IY1', ' EH1 S', '\\n', ' EH1 F', ' IY1', ' IY1', ' D IY1', ' EH1 S', ' T IY1', ' ', ' T IY1', ' EY1 CH', ' W AY1', ' ', ' EH1 L', ' AY1', ' JH IY1', ' EY1 CH', ' T IY1', ' EH1 S', ' T IY1', ' ', ' EH1 F', ' EH1 L', ' AH0 EY1', ' EH1 M', ' IY1', ' ', ' D AH1 B AH0 L Y UW0', ' AY1', ' T IY1', ' EY1 CH', ' ', ' EH1 S', ' IY1', ' EH1 L', ' EH1 F', ' EH1 S', ' Y UW1', ' B IY1', ' EH1 S', ' T IY1', ' AH0 EY1', ' EH1 N', ' T IY1', ' AY1', ' AH0 EY1', ' EH1 L', ' ', ' EH1 F', ' Y UW1', ' IY1', ' EH1 L', '\\n', ' EH1 M', ' AH0 EY1', ' K EY1', ' AY1', ' EH1 N', ' JH IY1', ' ', ' AH0 EY1', ' ', ' EH1 F', ' AH0 EY1', ' EH1 M', ' AY1', ' EH1 N', ' IY1', ' ', ' D AH1 B AH0 L Y UW0', ' EY1 CH', ' IY1', ' AA1 R', ' IY1', ' ', ' AH0 EY1', ' B IY1', ' Y UW1', ' EH1 N', ' D IY1', ' AH0 EY1', ' EH1 N', ' S IY1', ' IY1', ' ', ' EH1 L', ' AY1', ' IY1', ' EH1 S', '\\n', ' T IY1', ' EY1 CH', ' W AY1', ' EH1 S', ' IY1', ' EH1 L', ' EH1 F', ' ', ' T IY1', ' EY1 CH', ' W AY1', ' ', ' EH1 F', ' OW1', ' IY1', ' ', ' T IY1', ' OW1', ' ', ' T IY1', ' EY1 CH', ' W AY1', ' ', ' EH1 S', ' D AH1 B AH0 L Y UW0', ' IY1', ' IY1', ' T IY1', ' ', ' EH1 S', ' IY1', ' EH1 L', ' EH1 F', ' ', ' T IY1', ' OW1', ' OW1', ' ', ' S IY1', ' AA1 R', ' Y UW1', ' IY1', ' EH1 L', '\\n', ' T IY1', ' EY1 CH', ' OW1', ' Y UW1', ' ', ' T IY1', ' EY1 CH', ' AH0 EY1', ' T IY1', ' ', ' AH0 EY1', ' AA1 R', ' T IY1', ' ', ' EH1 N', ' OW1', ' D AH1 B AH0 L Y UW0', ' ', ' T IY1', ' EY1 CH', ' IY1', ' ', ' D AH1 B AH0 L Y UW0', ' OW1', ' AA1 R', ' EH1 L', ' D IY1', ' EH1 S', ' ', ' EH1 F', ' AA1 R', ' IY1', ' EH1 S', ' EY1 CH', ' ', ' OW1', ' AA1 R', ' EH1 N', ' AH0 EY1', ' EH1 M', ' IY1', ' EH1 N', ' T IY1', '\\n', ' AH0 EY1', ' EH1 N', ' D IY1', ' ', ' OW1', ' EH1 N', ' EH1 L', ' W AY1', ' ', ' EY1 CH', ' IY1', ' AA1 R', ' AH0 EY1', ' EH1 L', ' D IY1', ' ', ' T IY1', ' OW1', ' ', ' T IY1', ' EY1 CH', ' IY1', ' ', ' JH IY1', ' AH0 EY1', ' Y UW1', ' D IY1', ' W AY1', ' ', ' EH1 S', ' P IY1', ' AA1 R', ' AY1', ' EH1 N', ' JH IY1', '\\n', ' D AH1 B AH0 L Y UW0', ' AY1', ' T IY1', ' EY1 CH', ' AY1', ' EH1 N', ' ', ' T IY1', ' EY1 CH', ' AY1', ' EH1 N', ' IY1', ' ', ' OW1', ' D AH1 B AH0 L Y UW0', ' EH1 N', ' ', ' B IY1', ' Y UW1', ' D IY1', ' ', ' B IY1', ' Y UW1', ' AA1 R', ' AY1', ' IY1', ' EH1 S', ' T IY1', ' ', ' T IY1', ' EY1 CH', ' W AY1', ' ', ' S IY1', ' OW1', ' EH1 N', ' T IY1', ' IY1', ' EH1 N', ' T IY1', '\\n', ' AH0 EY1', ' EH1 N', ' D IY1', ' ', ' T IY1', ' IY1', ' EH1 N', ' D IY1', ' IY1', ' AA1 R', ' ', ' S IY1', ' EY1 CH', ' Y UW1', ' AA1 R', ' EH1 L', ' ', ' EH1 M', ' AH0 EY1', ' K EY1', ' IY1', ' EH1 S', ' T IY1', ' ', ' D AH1 B AH0 L Y UW0', ' AH0 EY1', ' EH1 S', ' T IY1', ' IY1', ' ', ' AY1', ' EH1 N', ' ', ' EH1 N', ' AY1', ' JH IY1', ' JH IY1', ' AH0 EY1', ' AA1 R', ' D IY1', ' AY1', ' EH1 N', ' JH IY1', '\\n', ' P IY1', ' AY1', ' T IY1', ' W AY1', ' ', ' T IY1', ' EY1 CH', ' IY1', ' ', ' D AH1 B AH0 L Y UW0', ' OW1', ' AA1 R', ' EH1 L', ' D IY1', ' ', ' OW1', ' AA1 R', ' ', ' IY1', ' EH1 L', ' EH1 S', ' IY1', ' ', ' T IY1', ' EY1 CH', ' AY1', ' EH1 S', ' ', ' JH IY1', ' EH1 L', ' Y UW1', ' T IY1', ' T IY1', ' OW1', ' EH1 N', ' ', ' B IY1', ' IY1', '\\n', ' T IY1', ' OW1', ' ', ' IY1', ' AH0 EY1', ' T IY1', ' ', ' T IY1', ' EY1 CH', ' IY1', ' ', ' D AH1 B AH0 L Y UW0', ' OW1', ' AA1 R', ' EH1 L', ' D IY1', ' EH1 S', ' ', ' D IY1', ' Y UW1', ' IY1', ' ', ' B IY1', ' W AY1', ' ', ' T IY1', ' EY1 CH', ' IY1', ' ', ' JH IY1', ' AA1 R', ' AH0 EY1', ' V IY1', ' IY1', ' ', ' AH0 EY1', ' EH1 N', ' D IY1', ' ', ' T IY1', ' EY1 CH', ' IY1', ' IY1']\n"
     ]
    }
   ],
   "source": [
    "data = Data()\n",
    "poems_punc = data.text_to_poems('sonnets.txt')\n",
    "poems_no_punc = data.remove_punctuation(poems_punc)\n",
    "#poems_words = data.poems_to_words(poems_no_punc)\n",
    "poems, slang = data.poems_to_phonemes(poems_no_punc)\n",
    "\n",
    "print(poems[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sim_matrix(poems, comparison):\n",
    "    pass\n",
    "    return sim_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What types of things do I neeed to to compare\n",
    "def compare(comparison='Basic'):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### phone2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "def word2vec():\n",
    "    model = Word2Vec(sentences, min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the poems using traditional methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poems_titled = text_to_poems()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate cosine distances b/w poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'poems' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-943aeb369675>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#print(pairwise_similarity)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'poems' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "def cosine_distance(poems):\n",
    "    tdidf = TfidfVectorizer().fit_transform(poems)\n",
    "    # Why does multiplying by transpose give you pairwise similarity?\n",
    "    pairwise_similarity = tdidf * tdidf.T\n",
    "    pw = pairwise_similarity.todense()\n",
    "    cosine_distance = 1 - pw\n",
    "    return cosine_distance\n",
    "\n",
    "#print(pairwise_similarity)\n",
    "dm = cosine_distance(poems)\n",
    "tree = nj(dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates distance matrix from any distances\n",
    "def distance_matrix(poems, distance_function):\n",
    "    distance_ matrix = [[]]\n",
    "    for i in range(len(poems)):\n",
    "        for j in range(len(poems)):\n",
    "            distance_matrix[i][j] = distance_function(poem[i], poem[j])\n",
    "    return distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the Jaccard distance for all pairs of poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the Jaccard distance for all pairs of poems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the neighbor joining algorithm on any given distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the neighbor joining method on distance matrices and return phylogenic tree:\n",
    "def neighbor_joining(distances):\n",
    "    data= distances\n",
    "    ids = list('abcde')\n",
    "    dm = DistanceMatrix(data, ids)\n",
    "    tree = nj(dm)\n",
    "    print(tree)\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      " AY1 F R AH1 M F EH1 R IH0 S T K R IY1 CH ER0 Z W IY1 D IH0 Z AY1 ER0 IH2 N K R IY1 S IH1 N K R IY2 S\n"
     ]
    }
   ],
   "source": [
    "# Words to phonemes where each poem is a list of lines, and each line is a string of phonemes\n",
    "def words_to_phonemes(poems):\n",
    "    phonemes = []\n",
    "    slang = []\n",
    "    \n",
    "    for poem in poems:\n",
    "        poem_phones = []\n",
    "        for line in poem:\n",
    "            line_phones = \"\"\n",
    "            for word in line:\n",
    "                p = prn.phones_for_word(word)\n",
    "    \n",
    "                if len(p) == 1:\n",
    "                    for item in p:\n",
    "                        line_phones = line_phones + \" \" + item\n",
    "                elif len(p) > 1:\n",
    "                    # TODO fix this hack by figuring out which pronunciation is best instead of just choosing the 1st\n",
    "                    for item in p:\n",
    "                        line_phones = line_phones + \" \" + item\n",
    "                else: # the word is not in the pronouncing dictionary\n",
    "                    slang.append(word)\n",
    "                    line_phones = line_phones + word\n",
    "                    \n",
    "            poem_phones.append(line_phones)\n",
    "                \n",
    "        phonemes.append(poem_phones)\n",
    "    \n",
    "    return phonemes, slang\n",
    "\n",
    "poems_punc = text_to_poems()\n",
    "poems_no_punc = remove_punctuation(poems_punc)\n",
    "poems_words = poems_to_words(poems_no_punc)\n",
    "poems, slang = words_to_phonemes(poems_words)\n",
    "print(len(poems[12][0]))\n",
    "print(poems[0][0])\n",
    "#print(phonemes[13][0][1][0].split())\n",
    "#print(len(phonemes))\n",
    "#print(len(slang))\n",
    "#print(phonemes)\n",
    "#print(phonemes[0][0][0][0])\n",
    "#print(poems[0][0][2][0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.269480519480524"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "pairs = defaultdict()\n",
    "\n",
    "#pairs = {}\n",
    "#for poem in poems:\n",
    "for lines in poems:\n",
    "    for line in lines:\n",
    "        #print(line + 'line')\n",
    "        lw = line.split()\n",
    "        for c, v in enumerate(lw):\n",
    "            pair = lw[c-1] + lw[c]\n",
    "            if pair in pairs:\n",
    "                pairs[pair] += 1\n",
    "            else:\n",
    "                pairs[pair] = 1\n",
    "\n",
    "c = Counter(pairs) \n",
    "c.most_common()\n",
    "sum(pairs.values())/154/10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'l' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-6c3cc4fe8f17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m#print(j)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mpair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;31m#print(pair)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'l' is not defined"
     ]
    }
   ],
   "source": [
    "# Find the sounds patterns that are most common:\n",
    "# Count up 2-phoneme sounds that occur in the text\n",
    "\n",
    "# Create the pairs\n",
    "pairs = {}\n",
    "for poem in poems:\n",
    "    for line in poems[0]:\n",
    "        pass\n",
    "        #print(line)\n",
    "            #print(phonemes.split())\n",
    "            #for items in phonemes.split():\n",
    "                #print(item)\n",
    "                    # If item[count] is a V of AH1 or phoneme piece\n",
    "                #print(item)\n",
    "                #print(type(item[count]))\n",
    "                \n",
    "        \n",
    "                #print(count, item)\n",
    "            #print(item)\n",
    "        \n",
    "    #for line in poems\n",
    "\n",
    "# Count the pairs\n",
    "#pairs\n",
    "for poem in poems:\n",
    "    for line in poems:\n",
    "        for j in range(len(line)-1):\n",
    "        #print(j)\n",
    "            pair = line[j] + line[j+1]\n",
    "            #print(pair)\n",
    "        #line_split = line.split()\n",
    "        #print(line_split)\n",
    "    #line = poems[0]\n",
    "    #print(line)\n",
    "\n",
    "for poem in poems:\n",
    "    for line in poems:\n",
    "        line = poems[0][0].split()\n",
    "    for j in range(len(line)-1):\n",
    "        #print(j)\n",
    "        pair = l[j] + l[j+1]\n",
    "        #print(pair)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO figure out how to get the roman numerals out \n",
    "import re\n",
    "re.compile('^M{0,4}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-268-7634e0671a48>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-268-7634e0671a48>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    def make_one_hot(poems[0], C=39):\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 39 phonemes in \n",
    "def make_one_hot(poems[0], C=39):\n",
    "    '''\n",
    "    Converts an integer label torch.autograd.Variable to a one-hot Variable.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : torch.autograd.Variable of torch.cuda.LongTensor\n",
    "        N x 1 x H x W, where N is batch size. \n",
    "        Each value is an integer representing correct classification.\n",
    "    C : integer. \n",
    "        number of classes in labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    target : torch.autograd.Variable of torch.cuda.FloatTensor\n",
    "        N x C x H x W, where C is class number. One-hot encoded.\n",
    "    '''\n",
    "    one_hot = torch.cuda.FloatTensor(labels.size(0), C, labels.size(2), labels.size(3)).zero_()\n",
    "    target = one_hot.scatter_(1, labels.data, 1)\n",
    "    \n",
    "    target = Variable(target)\n",
    "        \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "code_folding": [
     1
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['AY1', 'F R AH1 M', 'F EH1 R IH0 S T', 'K R IY1 CH ER0 Z', 'W IY1', 'D IH0 Z AY1 ER0', 'IH2 N K R IY1 S'], ['DH AE1 T', 'DH EH1 R B AY1', 'beautys', 'R OW1 Z', 'M AY1 T', 'N EH1 V ER0', 'D AY1'], ['B AH1 T', 'AE1 Z', 'DH AH0', 'riper', 'SH UH1 D', 'B AY1', 'T AY1 M', 'D IH0 S IY1 S'], ['HH IH1 Z', 'T EH1 N D ER0', 'EH1 R', 'M AY1 T', 'B EH1 R', 'HH IH1 Z', 'M EH1 M ER0 IY0'], ['B AH1 T', 'DH AW1', 'K AA1 N T R AE0 K T AH0 D', 'T UW1', 'DH AY1 N', 'OW1 N', 'B R AY1 T', 'AY1 Z'], ['feedst', 'DH AY1', 'lightst', 'F L EY1 M', 'W IH1 DH', 'selfsubstantial', 'F Y UW1 AH0 L'], ['M EY1 K IH0 NG', 'AH0', 'F AE1 M AH0 N', 'W EH1 R', 'AH0 B AH1 N D AH0 N S', 'L AY1 Z'], ['DH AY2 S EH1 L F', 'DH AY1', 'F OW1', 'T UW1', 'DH AY1', 'S W IY1 T', 'S EH1 L F', 'T UW1', 'K R UW1 AH0 L'], ['DH AW1', 'DH AE1 T', 'AA1 R T', 'N AW1', 'DH AH0', 'W ER1 L D Z', 'F R EH1 SH', 'AO1 R N AH0 M AH0 N T'], ['AH0 N D', 'OW1 N L IY0', 'HH EH1 R AH0 L D', 'T UW1', 'DH AH0', 'G AO1 D IY0', 'S P R IH1 NG'], ['W IH0 DH IH1 N', 'DH AY1 N', 'OW1 N', 'B AH1 D', 'buriest', 'DH AY1', 'K AA1 N T EH0 N T'], ['AH0 N D', 'T EH1 N D ER0', 'churl', 'makest', 'W EY1 S T', 'IH0 N', 'niggarding'], ['P IH1 T IY0', 'DH AH0', 'W ER1 L D', 'AO1 R', 'EH1 L S', 'DH IH1 S', 'glutton', 'B IY1'], ['T UW1', 'IY1 T', 'DH AH0', 'W ER1 L D Z', 'D UW1', 'B AY1', 'DH AH0', 'G R EY1 V', 'AH0 N D', 'DH IY1']]\n"
     ]
    }
   ],
   "source": [
    "# Words to phonemes where each poem is a list of lines, and each line is a list of phonemes\n",
    "def words_to_phonemes(poems):\n",
    "    phonemes = []\n",
    "    slang = []\n",
    "    \n",
    "    for poem in poems:\n",
    "        poem_phones = []\n",
    "        for line in poem:\n",
    "            line_phones = []\n",
    "            \n",
    "            for word in line:\n",
    "                p = prn.phones_for_word(word)\n",
    "    \n",
    "                if len(p) == 1:\n",
    "                    line_phones.append(p[0])\n",
    "                elif len(p) > 1:\n",
    "                    # TODO fix this hack by figuring out which pronunciation is best instead of just choosing the 1st\n",
    "                    line_phones.append(str(p[0]))\n",
    "                elif len(p) == 0: # the word is not in the pronouncing dictionary\n",
    "                    #print(word)\n",
    "                    slang.append(word)\n",
    "                    line_phones.append(word)\n",
    "                else: \n",
    "                    print('Not Good')\n",
    "            \n",
    "            poem_phones.append(line_phones)\n",
    "                \n",
    "        phonemes.append(poem_phones)\n",
    "    \n",
    "    return phonemes, slang\n",
    "\n",
    "poems_punc = text_to_poems()\n",
    "poems_no_punc = remove_punctuation(poems_punc)\n",
    "poems_words = poems_to_words(poems_no_punc)\n",
    "poems, slang = words_to_phonemes(poems_words)\n",
    "\n",
    "print(poems[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['AY1']\n",
      "['F', 'R', 'AH1', 'M']\n",
      "['F', 'EH1', 'R', 'IH0', 'S', 'T']\n",
      "['K', 'R', 'IY1', 'CH', 'ER0', 'Z']\n",
      "['W', 'IY1']\n",
      "['D', 'IH0', 'Z', 'AY1', 'ER0']\n",
      "['IH2', 'N', 'K', 'R', 'IY1', 'S']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-295-dca1130c4798>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Select by sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#print(poem[0][2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphonemes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Select by word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#print(poem[0][3])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for poem in results:\n",
    "    print(len(results))\n",
    "    for i in range(len(poem)):\n",
    "        #print(len(poem))\n",
    "    # Select by sentence\n",
    "    #print(poem[0][2])\n",
    "        print(phonemes[0][0][i][0].split())\n",
    "    # Select by word\n",
    "    #print(poem[0][3])\n",
    "    #print(results[0][0][0][i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    poems_punc = text_to_poems()\n",
    "    poems_no_punc = remove_punctuation(poems_punc)\n",
    "    poems_words = poems_to_words(poems_no_punc)\n",
    "    phonemes, slang = words_to_phonemes(poems_words)\n",
    "    return phonemes, slang\n",
    "\n",
    "#results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO when there are multiple pronunciations available, choose the one that fits that \n",
    "# metrical pattern\n",
    "# calculate the metrical pattern of the whole poem -> use this to find the local pattern\n",
    "# use the local pattern to figure out what stress we want to put in\n",
    "# compare stresses of different pronunciations, and choose the first one that matches\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_poem(poem):\n",
    "    words = []\n",
    "    poem_phonemes = []\n",
    "    poem = poem.lower()\n",
    "    poem_no_punc = poem.translate(str.maketrans('','',string.punctuation))\n",
    "    words.append(poem_no_punc)#.split('\\n'))\n",
    "    words = [word for word in words]\n",
    "    for word in words:\n",
    "        poem_phonemes.append(prn.phones_for_word(word))\n",
    "                             \n",
    "    return poem_phonemes\n",
    "\n",
    "\n",
    "a = map(clean_poem, [poem for poem in poems])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the sylable count, and use it to make the data into a matrix\n",
    "# Put every 10 sylables into a list or matrix -> should I use numpy?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = file.read().split('\\n\\n')\n",
    "#print(poems_list)\n",
    "#poems_list = [item.lower() for item.split('\\n') in data]\n",
    "\n",
    "#poems_list = [p.replace('\\n',' ') for p in data]\n",
    "\n",
    "#print(poems_clean[1])\n",
    "#print(poem.split('\\n')[0:10] for poem in poems_clean)        \n",
    "#print(type(poems_list[100].split('\\n')[0]))\n",
    "#print(poems_list[101].split('\\n')[0:100])\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-492-242d2c1a643c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpoem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mphoneme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                 \u001b[0mphonemes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoneme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word' is not defined"
     ]
    }
   ],
   "source": [
    "for poem in poems:\n",
    "    for line in poem:\n",
    "        for words in line:\n",
    "            for phoneme in word:\n",
    "                phonemes.append(phoneme)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a text file with all the poems returns a list of poems with titles and no punctuation\n",
    "def text_to_poems():\n",
    "    with open('sonnets.txt', 'r') as file:\n",
    "        poems_list = file.read().split('\\n\\n')\n",
    "        \n",
    "        # Poems and their titles got split up when parsing - reunite them\n",
    "        poems_titled = []\n",
    "        for i in range(0, (int(len(poems_list) - 1)), 2):\n",
    "            poem_with_title = poems_list[i] + \" \" + poems_list[i+1]\n",
    "            poems_titled.append(poem_with_title)\n",
    "               \n",
    "    return poems_titled\n",
    "\n",
    "#poems_punc = text_to_poems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all words lowercase and make each line into a list of word. Returns list of lists\n",
    "def poems_to_words(poems):\n",
    "    poems_list = []\n",
    "    for poem in poems:\n",
    "        lines = list(map(lambda x:x.lower(), poem.split('\\n')))\n",
    "        poem= [l.split() for l in lines]\n",
    "        poems_list.append(poem)\n",
    "        \n",
    "    return poems_list\n",
    "\n",
    "#poems_punc = text_to_poems()\n",
    "#poems_no_punc = remove_punctuation(poems_punc)\n",
    "#poems_words = poems_to_words(poems_no_punc)\n",
    "#poems_words[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a list of poems and returns a list of poems, with punctuation removed from each poem\n",
    "def remove_punctuation(poems_punc):\n",
    "    poems = []\n",
    "    for poem in poems_punc:\n",
    "        poem_phonemes = []\n",
    "        poem_no_punc = poem.translate(str.maketrans('','',string.punctuation))\n",
    "        poems.append(poem_no_punc)\n",
    "\n",
    "    return poems\n",
    "\n",
    "#poems_punc = text_to_poems()\n",
    "#poems_no_punc = remove_punctuation(poems_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Poems and their titles got split up when parsing - reunite them\n",
    "    for i in range(0, (int(len(poems_clean) - 1)), 2):\n",
    "        #poem_with_title = poems_raw[i] + \" \" + poems_raw[i+1]\n",
    "        poem = poems_clean[i+1]\n",
    "        poems.append(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet():\n",
    "    def __init__():\n",
    "        self.slang = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poem_to_phonemes(lines):\n",
    "    \n",
    "    '''Make all words lowercase and make each line into a list of word. Returns list of lists '''\n",
    "    \n",
    "    for poem in poems:\n",
    "        poem_phones = []\n",
    "\n",
    "        for line in poem:\n",
    "            line_phones = \"\"\n",
    "            for word in line:\n",
    "                p = prn.phones_for_word(word)\n",
    "\n",
    "                if len(p) == 1:\n",
    "                    for item in p:\n",
    "                        line_phones = line_phones + \" \" + item\n",
    "                elif len(p) > 1:\n",
    "                    # TODO fix this hack by figuring out which pronunciation is best instead of just choosing the 1st\n",
    "                    for item in p:\n",
    "                        line_phones = line_phones + \" \" + item\n",
    "                else: # the word is not in the pronouncing dictionary\n",
    "                    self.lang.append(word)\n",
    "                    line_phones = line_phones + word\n",
    "\n",
    "            poem_phones.append(line_phones)\n",
    "\n",
    "        phonemes.append(poem_phones)\n",
    "\n",
    "    return self.poem_phonemes"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "shakespeare-env",
   "language": "python",
   "name": "shakespeare-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
