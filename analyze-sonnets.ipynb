{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pronouncing as prn\n",
    "import string\n",
    "import itertools\n",
    "import torch\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a text file with all the poems returns a list of poems with titles and no punctuation\n",
    "def text_to_poems():\n",
    "    with open('sonnets.txt', 'r') as file:\n",
    "        poems_list = file.read().split('\\n\\n')\n",
    "        \n",
    "        # Poems and their titles got split up when parsing - reunite them\n",
    "        poems_titled = []\n",
    "        for i in range(0, (int(len(poems_list) - 1)), 2):\n",
    "            poem_with_title = poems_list[i] + \" \" + poems_list[i+1]\n",
    "            poems_titled.append(poem_with_title)\n",
    "               \n",
    "    return poems_titled\n",
    "\n",
    "#poems_punc = text_to_poems()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in a list of poems and returns a list of poems, with punctuation removed from each poem\n",
    "def remove_punctuation(poems_punc):\n",
    "    poems = []\n",
    "    for poem in poems_punc:\n",
    "        poem_phonemes = []\n",
    "        poem_no_punc = poem.translate(str.maketrans('','',string.punctuation))\n",
    "        poems.append(poem_no_punc)\n",
    "\n",
    "    return poems\n",
    "\n",
    "#poems_punc = text_to_poems()\n",
    "#poems_no_punc = remove_punctuation(poems_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all words lowercase and make each line into a list of word. Returns list of lists\n",
    "def poems_to_words(poems):\n",
    "    poems_list = []\n",
    "    for poem in poems:\n",
    "        lines = list(map(lambda x:x.lower(), poem.split('\\n')))\n",
    "        poem= [l.split() for l in lines]\n",
    "        poems_list.append(poem)\n",
    "        \n",
    "    return poems_list\n",
    "\n",
    "#poems_punc = text_to_poems()\n",
    "#poems_no_punc = remove_punctuation(poems_punc)\n",
    "#poems_words = poems_to_words(poems_no_punc)\n",
    "#poems_words[0][1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122\n",
      " AY1 F R AH1 M F EH1 R IH0 S T K R IY1 CH ER0 Z W IY1 D IH0 Z AY1 ER0 IH2 N K R IY1 S IH1 N K R IY2 S\n"
     ]
    }
   ],
   "source": [
    "# Words to phonemes where each poem is a list of lines, and each line is a string of phonemes\n",
    "def words_to_phonemes(poems):\n",
    "    phonemes = []\n",
    "    slang = []\n",
    "    \n",
    "    for poem in poems:\n",
    "        poem_phones = []\n",
    "        for line in poem:\n",
    "            line_phones = \"\"\n",
    "            for word in line:\n",
    "                p = prn.phones_for_word(word)\n",
    "    \n",
    "                if len(p) == 1:\n",
    "                    for item in p:\n",
    "                        line_phones = line_phones + \" \" + item\n",
    "                elif len(p) > 1:\n",
    "                    # TODO fix this hack by figuring out which pronunciation is best instead of just choosing the 1st\n",
    "                    for item in p:\n",
    "                        line_phones = line_phones + \" \" + item\n",
    "                else: # the word is not in the pronouncing dictionary\n",
    "                    slang.append(word)\n",
    "                    line_phones = line_phones + word\n",
    "                    \n",
    "            poem_phones.append(line_phones)\n",
    "                \n",
    "        phonemes.append(poem_phones)\n",
    "    \n",
    "    return phonemes, slang\n",
    "\n",
    "poems_punc = text_to_poems()\n",
    "poems_no_punc = remove_punctuation(poems_punc)\n",
    "poems_words = poems_to_words(poems_no_punc)\n",
    "poems, slang = words_to_phonemes(poems_words)\n",
    "print(len(poems[12][0]))\n",
    "print(poems[0][0])\n",
    "#print(phonemes[13][0][1][0].split())\n",
    "#print(len(phonemes))\n",
    "#print(len(slang))\n",
    "#print(phonemes)\n",
    "#print(phonemes[0][0][0][0])\n",
    "#print(poems[0][0][2][0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.269480519480524"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "pairs = defaultdict()\n",
    "\n",
    "#pairs = {}\n",
    "#for poem in poems:\n",
    "for lines in poems:\n",
    "    for line in lines:\n",
    "        #print(line + 'line')\n",
    "        lw = line.split()\n",
    "        for c, v in enumerate(lw):\n",
    "            pair = lw[c-1] + lw[c]\n",
    "            if pair in pairs:\n",
    "                pairs[pair] += 1\n",
    "            else:\n",
    "                pairs[pair] = 1\n",
    "\n",
    "c = Counter(pairs) \n",
    "c.most_common()\n",
    "sum(pairs.values())/154/10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Find the sounds patterns that are most common:\n",
    "# Count up 2-phoneme sounds that occur in the text\n",
    "\n",
    "# Create the pairs\n",
    "pairs = {}\n",
    "for poem in poems:\n",
    "    for line in poems[0]:\n",
    "        pass\n",
    "        #print(line)\n",
    "            #print(phonemes.split())\n",
    "            #for items in phonemes.split():\n",
    "                #print(item)\n",
    "                    # If item[count] is a V of AH1 or phoneme piece\n",
    "                #print(item)\n",
    "                #print(type(item[count]))\n",
    "                \n",
    "        \n",
    "                #print(count, item)\n",
    "            #print(item)\n",
    "        \n",
    "    #for line in poems\n",
    "\n",
    "# Count the pairs\n",
    "#pairs\n",
    "for poem in poems:\n",
    "    for line in poems:\n",
    "        for j in range(len(line)-1):\n",
    "        #print(j)\n",
    "            pair = line[j] + line[j+1]\n",
    "            #print(pair)\n",
    "        #line_split = line.split()\n",
    "        #print(line_split)\n",
    "    #line = poems[0]\n",
    "    #print(line)\n",
    "\n",
    "for poem in poems:\n",
    "    for line in poems:\n",
    "        line = poems[0][0].split()\n",
    "    for j in range(len(line)-1):\n",
    "        #print(j)\n",
    "        pair = l[j] + l[j+1]\n",
    "        #print(pair)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO figure out how to get the roman numerals out \n",
    "import re\n",
    "re.compile('^M{0,4}(CM|CD|D?C{0,3})(XC|XL|L?X{0,3})(IX|IV|V?I{0,3})$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-268-7634e0671a48>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-268-7634e0671a48>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    def make_one_hot(poems[0], C=39):\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# 39 phonemes in \n",
    "def make_one_hot(poems[0], C=39):\n",
    "    '''\n",
    "    Converts an integer label torch.autograd.Variable to a one-hot Variable.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : torch.autograd.Variable of torch.cuda.LongTensor\n",
    "        N x 1 x H x W, where N is batch size. \n",
    "        Each value is an integer representing correct classification.\n",
    "    C : integer. \n",
    "        number of classes in labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    target : torch.autograd.Variable of torch.cuda.FloatTensor\n",
    "        N x C x H x W, where C is class number. One-hot encoded.\n",
    "    '''\n",
    "    one_hot = torch.cuda.FloatTensor(labels.size(0), C, labels.size(2), labels.size(3)).zero_()\n",
    "    target = one_hot.scatter_(1, labels.data, 1)\n",
    "    \n",
    "    target = Variable(target)\n",
    "        \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['AY1', 'F R AH1 M', 'F EH1 R IH0 S T', 'K R IY1 CH ER0 Z', 'W IY1', 'D IH0 Z AY1 ER0', 'IH2 N K R IY1 S'], ['DH AE1 T', 'DH EH1 R B AY1', 'beautys', 'R OW1 Z', 'M AY1 T', 'N EH1 V ER0', 'D AY1'], ['B AH1 T', 'AE1 Z', 'DH AH0', 'riper', 'SH UH1 D', 'B AY1', 'T AY1 M', 'D IH0 S IY1 S'], ['HH IH1 Z', 'T EH1 N D ER0', 'EH1 R', 'M AY1 T', 'B EH1 R', 'HH IH1 Z', 'M EH1 M ER0 IY0'], ['B AH1 T', 'DH AW1', 'K AA1 N T R AE0 K T AH0 D', 'T UW1', 'DH AY1 N', 'OW1 N', 'B R AY1 T', 'AY1 Z'], ['feedst', 'DH AY1', 'lightst', 'F L EY1 M', 'W IH1 DH', 'selfsubstantial', 'F Y UW1 AH0 L'], ['M EY1 K IH0 NG', 'AH0', 'F AE1 M AH0 N', 'W EH1 R', 'AH0 B AH1 N D AH0 N S', 'L AY1 Z'], ['DH AY2 S EH1 L F', 'DH AY1', 'F OW1', 'T UW1', 'DH AY1', 'S W IY1 T', 'S EH1 L F', 'T UW1', 'K R UW1 AH0 L'], ['DH AW1', 'DH AE1 T', 'AA1 R T', 'N AW1', 'DH AH0', 'W ER1 L D Z', 'F R EH1 SH', 'AO1 R N AH0 M AH0 N T'], ['AH0 N D', 'OW1 N L IY0', 'HH EH1 R AH0 L D', 'T UW1', 'DH AH0', 'G AO1 D IY0', 'S P R IH1 NG'], ['W IH0 DH IH1 N', 'DH AY1 N', 'OW1 N', 'B AH1 D', 'buriest', 'DH AY1', 'K AA1 N T EH0 N T'], ['AH0 N D', 'T EH1 N D ER0', 'churl', 'makest', 'W EY1 S T', 'IH0 N', 'niggarding'], ['P IH1 T IY0', 'DH AH0', 'W ER1 L D', 'AO1 R', 'EH1 L S', 'DH IH1 S', 'glutton', 'B IY1'], ['T UW1', 'IY1 T', 'DH AH0', 'W ER1 L D Z', 'D UW1', 'B AY1', 'DH AH0', 'G R EY1 V', 'AH0 N D', 'DH IY1']]\n"
     ]
    }
   ],
   "source": [
    "# Words to phonemes where each poem is a list of lines, and each line is a list of phonemes\n",
    "def words_to_phonemes(poems):\n",
    "    phonemes = []\n",
    "    slang = []\n",
    "    \n",
    "    for poem in poems:\n",
    "        poem_phones = []\n",
    "        for line in poem:\n",
    "            line_phones = []\n",
    "            \n",
    "            for word in line:\n",
    "                p = prn.phones_for_word(word)\n",
    "    \n",
    "                if len(p) == 1:\n",
    "                    line_phones.append(p[0])\n",
    "                elif len(p) > 1:\n",
    "                    # TODO fix this hack by figuring out which pronunciation is best instead of just choosing the 1st\n",
    "                    line_phones.append(str(p[0]))\n",
    "                elif len(p) == 0: # the word is not in the pronouncing dictionary\n",
    "                    #print(word)\n",
    "                    slang.append(word)\n",
    "                    line_phones.append(word)\n",
    "                else: \n",
    "                    print('Not Good')\n",
    "            \n",
    "            poem_phones.append(line_phones)\n",
    "                \n",
    "        phonemes.append(poem_phones)\n",
    "    \n",
    "    return phonemes, slang\n",
    "\n",
    "poems_punc = text_to_poems()\n",
    "poems_no_punc = remove_punctuation(poems_punc)\n",
    "poems_words = poems_to_words(poems_no_punc)\n",
    "poems, slang = words_to_phonemes(poems_words)\n",
    "\n",
    "print(poems[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "['AY1']\n",
      "['F', 'R', 'AH1', 'M']\n",
      "['F', 'EH1', 'R', 'IH0', 'S', 'T']\n",
      "['K', 'R', 'IY1', 'CH', 'ER0', 'Z']\n",
      "['W', 'IY1']\n",
      "['D', 'IH0', 'Z', 'AY1', 'ER0']\n",
      "['IH2', 'N', 'K', 'R', 'IY1', 'S']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-295-dca1130c4798>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Select by sentence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#print(poem[0][2])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphonemes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Select by word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#print(poem[0][3])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for poem in results:\n",
    "    print(len(results))\n",
    "    for i in range(len(poem)):\n",
    "        #print(len(poem))\n",
    "    # Select by sentence\n",
    "    #print(poem[0][2])\n",
    "        print(phonemes[0][0][i][0].split())\n",
    "    # Select by word\n",
    "    #print(poem[0][3])\n",
    "    #print(results[0][0][0][i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    poems_punc = text_to_poems()\n",
    "    poems_no_punc = remove_punctuation(poems_punc)\n",
    "    poems_words = poems_to_words(poems_no_punc)\n",
    "    phonemes, slang = words_to_phonemes(poems_words)\n",
    "    return phonemes, slang\n",
    "\n",
    "#results = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO when there are multiple pronunciations available, choose the one that fits that \n",
    "# metrical pattern\n",
    "# calculate the metrical pattern of the whole poem -> use this to find the local pattern\n",
    "# use the local pattern to figure out what stress we want to put in\n",
    "# compare stresses of different pronunciations, and choose the first one that matches\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_poem(poem):\n",
    "    words = []\n",
    "    poem_phonemes = []\n",
    "    poem = poem.lower()\n",
    "    poem_no_punc = poem.translate(str.maketrans('','',string.punctuation))\n",
    "    words.append(poem_no_punc)#.split('\\n'))\n",
    "    words = [word for word in words]\n",
    "    for word in words:\n",
    "        poem_phonemes.append(prn.phones_for_word(word))\n",
    "                             \n",
    "    return poem_phonemes\n",
    "\n",
    "\n",
    "a = map(clean_poem, [poem for poem in poems])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the sylable count, and use it to make the data into a matrix\n",
    "# Put every 10 sylables into a list or matrix -> should I use numpy?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #data = file.read().split('\\n\\n')\n",
    "        #print(poems_list)\n",
    "        #poems_list = [item.lower() for item.split('\\n') in data]\n",
    "\n",
    "        #poems_list = [p.replace('\\n',' ') for p in data]\n",
    "                \n",
    "        #print(poems_clean[1])\n",
    "        #print(poem.split('\\n')[0:10] for poem in poems_clean)        \n",
    "        #print(type(poems_list[100].split('\\n')[0]))\n",
    "        #print(poems_list[101].split('\\n')[0:100])\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-492-242d2c1a643c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpoem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mphoneme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                 \u001b[0mphonemes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphoneme\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word' is not defined"
     ]
    }
   ],
   "source": [
    "for poem in poems:\n",
    "    for line in poem:\n",
    "        for words in line:\n",
    "            for phoneme in word:\n",
    "                phonemes.append(phoneme)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "shakespeare-env",
   "language": "python",
   "name": "shakespeare-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
